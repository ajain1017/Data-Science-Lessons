{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center> Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"cnn_features.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"cnn.gif\" height=600 width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <center> https://www.youtube.com/watch?v=f0t-OCG79-U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <center> Kernel Examples </center><br>\n",
    "<center> <a href=\"https://setosa.io/ev/image-kernels/\">https://setosa.io/ev/image-kernels/</a> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <center> Padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"padding.png\" height=600 width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <center> Stride"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"stride2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"max_pooling.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <center> Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"cnn_fashion.png\" height=600 width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"cnn_car.gif\" height=600 width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <center> Deep Fakes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"trump_fallon.gif\" height=600 width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <center> CNN in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images/255\n",
    "test_images = test_images/255\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "train_images = train_images.reshape(len(train_images), 28, 28, 1)\n",
    "test_images = test_images.reshape(len(test_images), 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 64)          51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 62,346\n",
      "Trainable params: 62,346\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32,(5,5),activation='relu',input_shape=(28,28,1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (5,5), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 28s 459us/step - loss: 0.1730 - acc: 0.9496\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 30s 503us/step - loss: 0.0519 - acc: 0.9845\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 32s 529us/step - loss: 0.0357 - acc: 0.9892\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 31s 513us/step - loss: 0.0276 - acc: 0.9911\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 30s 498us/step - loss: 0.0222 - acc: 0.9931\n",
      "10000/10000 [==============================] - 2s 171us/step\n",
      "Test accuracy: 0.991\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels,\n",
    "          batch_size=64,\n",
    "          epochs=5,\n",
    "          verbose=1)\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <center> Activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Using the Cifar-10 images (https://drive.google.com/file/d/12EC46QuW1yN1rZTe-B7WuhJGnKrbCg_E/view?usp=sharing) and the labels found in trainLabels.csv, build a neural network that uses CNN layers to classify images to one of 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "## load image data\n",
    "file = open('cifar_train_images','rb')\n",
    "images = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## load label data\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 28.8x28.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "## display an image (real size)\n",
    "def display_image_in_actual_size(im_data):\n",
    "    dpi = 80\n",
    "    height, width, depth = im_data.shape\n",
    "    # What size does the figure need to be in inches to fit the image?\n",
    "    figsize = width / float(dpi), height / float(dpi)\n",
    "    # Create a figure of the right size with one axes that takes up the full figure\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = fig.add_axes([0, 0, 1, 1])\n",
    "    # Hide spines, ticks, etc.\n",
    "    ax.axis('off')\n",
    "    # Display the image.\n",
    "    ax.imshow(im_data, cmap='gray')\n",
    "    plt.show()\n",
    "display_image_in_actual_size(images[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x134263a20>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## disply an image\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "y = pd.read_csv('trainLabels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.drop('id', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y.label.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## scale the train images and convert labels to categorical format\n",
    "images = images/255\n",
    "from keras.utils import np_utils\n",
    "y = y.label.astype('category')\n",
    "y = y.cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np_utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "## perform a train test split with test_size = 0.2 and random_state = 4.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, y, test_size = 0.2, random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 32, 32, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(40000, 10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(X_train.shape)\n",
    "display(X_test.shape)\n",
    "display(y_train.shape)\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gaussian_noise_7 (GaussianNo (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 10, 10, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 512)               819712    \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 890,410\n",
      "Trainable params: 890,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/500\n",
      "40000/40000 [==============================] - 156s 4ms/step - loss: 1.6593 - acc: 0.3901 - val_loss: 1.3607 - val_acc: 0.5050\n",
      "Epoch 2/500\n",
      "40000/40000 [==============================] - 212s 5ms/step - loss: 1.2894 - acc: 0.5341 - val_loss: 1.1899 - val_acc: 0.5714\n",
      "Epoch 3/500\n",
      "40000/40000 [==============================] - 177s 4ms/step - loss: 1.1472 - acc: 0.5903 - val_loss: 1.0670 - val_acc: 0.6227\n",
      "Epoch 4/500\n",
      "40000/40000 [==============================] - 174s 4ms/step - loss: 1.0445 - acc: 0.6307 - val_loss: 0.9900 - val_acc: 0.6525\n",
      "Epoch 5/500\n",
      "40000/40000 [==============================] - 168s 4ms/step - loss: 0.9816 - acc: 0.6537 - val_loss: 0.9805 - val_acc: 0.6610\n",
      "Epoch 6/500\n",
      "40000/40000 [==============================] - 158s 4ms/step - loss: 0.9260 - acc: 0.6716 - val_loss: 0.9088 - val_acc: 0.6839\n",
      "Epoch 7/500\n",
      "40000/40000 [==============================] - 148s 4ms/step - loss: 0.8833 - acc: 0.6842 - val_loss: 0.9157 - val_acc: 0.6840\n",
      "Epoch 00007: early stopping\n",
      "Train: 0.751, Test: 0.684\n"
     ]
    }
   ],
   "source": [
    "## build a neural network model\n",
    "## 1) use two Conv2D layers with 32 neurons each and a filter of (3,3) for both\n",
    "## 2) add a MaxPooling2D layer with pool_size=2,2\n",
    "## 3) add a dropout layer\n",
    "## 4) repeat the above but increase the number of neurons in the Conv2D lyaers to 64\n",
    "## 5) add a Flatten layer, a Dense layer with 512 neurons, and a dropout layer with a dropout fraction of 0.5\n",
    "## 6) add the final Dense output layer\n",
    "## 7) view the model summary\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import GaussianNoise\n",
    "\n",
    "model = Sequential()\n",
    "model.add(GaussianNoise(0.1, input_shape=(32,32,3)))\n",
    "model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Dropout(0.05))\n",
    "\n",
    "model.add(Conv2D(64,(3,3), activation='relu'))\n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Dropout(0.05))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# simple early stopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1) ## patience=200\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=500, verbose=1, callbacks = [es])\n",
    "\n",
    "_, train_acc = model.evaluate(X_train, y_train, verbose=0)\n",
    "_, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compile and fit the model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## now make some changes to try and increase test accuracy\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <center> Bonus </center>\n",
    "<center> Generate and inspect a confusion matrix of your models performance using at least 100 random samples from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
